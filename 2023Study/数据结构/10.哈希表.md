# 散列表

[TOC]

## 时间复杂度

插入、查找、删除时间复杂度O(1)
> 找到O(1),插入或者删除是O(K), = O(1) + O(K), 若K很小 = O(1)
> 注意：是大常数


tips: 10亿byte数据，等于1GB内存大小。

### 扩容时间复杂度

1、假如链表长度超过2就需要扩容，要扩容几次？
> 2->4->8 16 32 64
> 需要O(logN)
> 如果链表长度是k，就需要 $O(log_k{n})$ < $O(logn)$

2、扩容时间复杂度
> = 扩容次数 x 每次扩容(每次需要操作N个数)
> = O(logN) x O(N)
> = $O(nlogn)$

3、每次扩容的时间复杂度

### 离线扩容

空闲时间，可以做到空闲时间再去扩容哈希表。
理论上散列表是O(logn)，使用上是O(1)

### String

HashMap存Node，Node里面有String是整个小说，占用多大？8Byte
HashMap<Integer, String>按数值传递String？
HashMap存入基本数据类型的包装类，判断是否存在时，判断值。
其他对象判断引用。

1、哈希表插入是O(1)吗？不考虑数据长度
1. 如果是String = O(K)
2. 需要遍历String算出hash值
3. 大量String，需要算平均长度

## 哈希冲突
开放寻址法
公共溢出区

## 应用场景

### 对称/非对称加密
对称：相同秘钥，AES、DES、3DES
非对称：RSA、DSA、ECC

### MD5
1. HASH算法的应用，进行信息摘要
2. 散列到32byte，128bit的字符串
3. 不可逆、敏感

### 布隆过滤器

1、布隆过滤器是什么？
1. 模糊查找
1. 允许失误率（可以设计为万分之一）
2. 无删除行为
3. 拥有行为：插入、删除

2、场景一：URL 黑名单
1. 一百亿URL组成大文件，1个URL 64Byte。需要判断url是否可以访问。需要640G内存。

3、场景二：爬虫
1. 1000个线程爬网页，不希望同一个URL反复爬虫
2. 需要建立黑名单，直接跳过爬过的URL

4、场景三：秒杀系统，用户是否重复购买

4、布隆过滤器的失误行为
1. 黑 -> 白
2. 白 -> 黑
3. 布隆过滤器，不具有黑 -> 白的失误行为。

5、Bitarr、Bitmap
1. 能够做出一个数组，每位上是1bit？
2. bit[] 而不是 int[],占用空间从400byte下降为100/8 byte
```java
int[] arr = new int[10]; // 32bit * 10 = 320bit
// 如何拿到第178个bit的状态？
int status = (arr[178 / 32] >> (178 % 32)) & 1;
// 思路：先得到是第几个int
// 再获取到目标bit的数值是1还是0

// 设置为1
arr[178 / 32] = (arr[178 / 32]) | (1 << (178 % 32))
// 设置为0
arr[178 / 32] = (arr[178 / 32]) & ~(1 << (178 % 32))
```

6、位图就是特殊的布隆过滤器？？？

#### 实现

1、构造布隆过滤器（url黑名单版本）
1. 构造长度为m的bit[]数组，0~m-1
2. 将url-1 通过 k个 完全独立 hash函数，算出位置，在bit[]中标黑 // 👉 哈希冲突的散列集合法
3. 从url-1一直到url-100亿

2、如何检查：
1. 有url，通过k个 hash函数，检查是否都和黑名单对应
2. 全部对应，才匹配

3、如何确定k？如何确定m？
1. 最大因素：m
2. m决定失误率p(m=1,p=100%)
3. n和m决定k，随着k增加，失误率下降。k增加到一定程度（m消耗），失误率上升。

4、公式
```java
n = 样本量
p = 失误率 // 是否允许失误率？预期失误率多少？
```
1. 是否允许失误率？预期失误率多少？
2. 是否需要删除行为？

$$
m = -\frac{n \times lnP}{(ln2)^2}
$$
$$
k = -\frac{m}{n} \times ln2
$$
> k = 小数时，向上取整

举例：失误率万分之一
> 100亿64byte数据，从640G下降到26G

**实际失误率**
$$
P_{真实} = (1 - e^{-\frac{nk}{m}})^k
$$

// 样本大小，失误率

### 数据均衡

1、查询key，有高频key a个，中频key b个，低频key c个
1. 如果a、b、c都特别大，就代表很均衡（哈希不管谁多谁少）
2. 要选择出现概率都很高的数据作为key（比如身份证）(不能用国家名划分)
3. 要选择种类很多的key（不能用 男女 划分）


2、数据库分为逻辑端、数据端
1. 逻辑端：扩容，等操作都简单，从数据端查询即可
2. 数据端：扩容等操作复杂

## 哈希一致性算法

增加服务器：数据迁移，将计算出属于自己的数据迁移到自己。
减少服务器：把数据交给下一个服务器

### 虚拟节点

1、用于均分点（数据少的时候，以及服务器本身不均分）

2、增加服务器后，会负载不均衡，怎么办？

3、服务器m1有1000个代表节点（字符串）
1. 每个字符串算出hash值去抢环
```java
m1(a1,a2,...,a1000)
m2(b1,b2,...,b1000)
m3(c1,c2,...,c1000)
```

4、如何增加服务器？
1. m4增加1000个节点，均衡的从m1~m3服务器抢相等的

5、如何减少服务器？
1. 按比例交给其他服务器

6、虚拟节点可以按照比例帮助管控服务器
1. 性能好的服务器，可以分配2000个虚拟节点
2. 性能差的服务器，可以分配500个虚拟节点

7、虚拟节点拿数据和给数据很简单
1. 根据表格，可以很轻易的将a100的数据给b500


## Bitmap

1、40亿数据，找到在0~2^32中没有出现的数据。【1G内存】
1. 2^32/8 = 500MB 1bit出现还是没出现
2. 先都遍历40亿数据，描黑
3. 再遍历bit数组，找到一个没描黑的。就是
2、限制一：10MB内存，甚至是3KB内存【词频统计，不够】 
1. `2^32 / 512  = 8388608`(平分到`arr = int[512]`)
   > 512个int，就是2048byte（2KB）
2. 遍历40亿数据，`x / 8388608 = index`，就分配到 `arr[index]+++`，不够8388608的数据范围
3. 遍历40亿数据，找到第二步骤范围内的数据，继续分为512份。循环定位。（2、3、2、3...）缩小至范围1。
3、限制二：有限变量
1. 先二分


## 题目

### 设计RandomPool结构

该结构支持以下功能：
1. insert(key): 插入key时不重复添加
2. delete(key)：将key移除
3. getRandom()：等概率随机返回结构中任何一个key
要求：任何操作时间复杂度都是O(1)


解答：
```java
准备两个表:
map1(str->index)
map2(index->str)
int size = 0;


插入：
map1: str=“A” value=1
map2: index = 1 value="A"

Random: (int)(Math.random() * size)，可以拿到随机

删除：
// 不能直接
用最后一个数覆盖删除的那个数。不会有洞。
size--;
```
